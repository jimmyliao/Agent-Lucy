#!/usr/bin/env python3
"""
FastAPI Backend for Agent Lucy Web App
Supports: Real-time chat, conversation history, file upload, multi-user
"""

from fastapi import FastAPI, HTTPException, UploadFile, File, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse
from pydantic import BaseModel
from typing import List, Optional, Dict
import json
import asyncio
from datetime import datetime
from pathlib import Path
import os

# Azure AI imports
from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient

# Agent Framework imports
try:
    from agent_framework import ChatAgent, MCPStdioTool
    from agent_framework.azure import AzureAIAgentClient
    AGENT_FRAMEWORK_AVAILABLE = True
    MCP_AVAILABLE = True
except ImportError:
    AGENT_FRAMEWORK_AVAILABLE = False
    MCP_AVAILABLE = False
    ChatAgent = None
    AzureAIAgentClient = None
    MCPStdioTool = None

# Configuration
AZURE_ENDPOINT = os.getenv(
    "AZURE_ENDPOINT",
    "https://sjliao-8193-resource.services.ai.azure.com/api/projects/sjliao-8193"
)

# Initialize FastAPI app
app = FastAPI(
    title="Agent Lucy Web App",
    description="Chat with Agent Lucy - Azure AI Foundry Agent",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # For Cloudflare Pages
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Data models
class ChatMessage(BaseModel):
    role: str
    content: str
    timestamp: Optional[str] = None

class ChatRequest(BaseModel):
    message: str
    user_id: Optional[str] = "default"
    thread_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    thread_id: str
    timestamp: str

# In-memory storage (for demo - replace with database in production)
conversations: Dict[str, List[ChatMessage]] = {}
active_connections: Dict[str, WebSocket] = {}
mcp_tools: Dict[str, any] = {}  # Store active MCP tool instances

# Azure AI Client
credential = DefaultAzureCredential()
project_client = AIProjectClient(endpoint=AZURE_ENDPOINT, credential=credential)

# Get agent
def get_agent():
    """Get the agent-lucy agent"""
    agents = list(project_client.agents.list_agents())
    if not agents:
        raise HTTPException(status_code=404, detail="No agents found")

    for agent in agents:
        if "lucy" in agent.name.lower():
            return agent

    return agents[0]  # Return first agent if no lucy found

# MCP Tools Initialization
async def init_mcp_tools():
    """Initialize MCP tools for agent-lucy"""
    if not MCP_AVAILABLE:
        return {"status": "unavailable", "message": "MCP not installed"}

    tools_status = {}

    # GitHub MCP Tool
    try:
        # Try multiple environment variable names
        github_token = os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN") or os.getenv("GITHUB_API_KEN") or os.getenv("GITHUB_TOKEN")
        if github_token:
            github_tool = MCPStdioTool(
                name="github",
                command="npx",
                args=["-y", "@modelcontextprotocol/server-github"],
                env={"GITHUB_PERSONAL_ACCESS_TOKEN": github_token},
                description="GitHub repository operations and file management",
            )
            mcp_tools["github"] = github_tool
            tools_status["github"] = "configured"
        else:
            tools_status["github"] = "missing_token"
    except Exception as e:
        tools_status["github"] = f"error: {str(e)}"

    # Filesystem MCP Tool (限制在 uploads 目錄)
    try:
        upload_dir = Path("/tmp/agent-lucy-uploads")
        upload_dir.mkdir(exist_ok=True)

        filesystem_tool = MCPStdioTool(
            name="filesystem",
            command="npx",
            args=["-y", "@modelcontextprotocol/server-filesystem", str(upload_dir)],
            description="File system operations for uploaded files",
        )
        mcp_tools["filesystem"] = filesystem_tool
        tools_status["filesystem"] = "configured"
    except Exception as e:
        tools_status["filesystem"] = f"error: {str(e)}"

    # Memory MCP Tool
    try:
        memory_tool = MCPStdioTool(
            name="memory",
            command="npx",
            args=["-y", "@modelcontextprotocol/server-memory"],
            description="Knowledge graph-based persistent memory",
        )
        mcp_tools["memory"] = memory_tool
        tools_status["memory"] = "configured"
    except Exception as e:
        tools_status["memory"] = f"error: {str(e)}"

    return {
        "status": "initialized",
        "mcp_available": MCP_AVAILABLE,
        "tools": tools_status
    }

async def get_mcp_tools_list():
    """Get list of available MCP tools and their functions"""
    if not MCP_AVAILABLE or not mcp_tools:
        return []

    tools_info = []
    for tool_name, tool_instance in mcp_tools.items():
        try:
            # Connect to tool to get functions list
            if not tool_instance.is_connected:
                await tool_instance.connect()

            functions = [
                {
                    "name": func.name,
                    "description": func.description,
                }
                for func in tool_instance.functions
            ]

            tools_info.append({
                "tool": tool_name,
                "description": tool_instance.description,
                "functions": functions,
            })
        except Exception as e:
            tools_info.append({
                "tool": tool_name,
                "error": str(e)
            })

    return tools_info

# API Endpoints

@app.get("/")
async def root():
    """Serve the main HTML page"""
    html_file = Path(__file__).parent.parent / "public" / "index.html"
    if html_file.exists():
        return FileResponse(html_file)
    return {"message": "Agent Lucy API is running", "docs": "/docs"}

@app.get("/api/health")
async def health_check():
    """Health check endpoint"""
    try:
        agent = get_agent()
        return {
            "status": "healthy",
            "agent": agent.name,
            "model": agent.model,
            "mcp_available": MCP_AVAILABLE,
            "mcp_tools_count": len(mcp_tools)
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }

@app.post("/api/mcp/init")
async def initialize_mcp_tools():
    """Initialize MCP tools"""
    result = await init_mcp_tools()
    return result

@app.get("/api/mcp/tools")
async def list_mcp_tools():
    """List available MCP tools and their functions"""
    tools = await get_mcp_tools_list()
    return {
        "mcp_available": MCP_AVAILABLE,
        "tools": tools
    }

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Send a message to agent-lucy"""
    try:
        agent = get_agent()
        user_id = request.user_id

        # Initialize conversation if needed
        if user_id not in conversations:
            conversations[user_id] = []

        # Add user message to history
        user_msg = ChatMessage(
            role="user",
            content=request.message,
            timestamp=datetime.now().isoformat()
        )
        conversations[user_id].append(user_msg)

        # Create thread and run
        run = project_client.agents.create_thread_and_run(
            agent_id=agent.id,
            thread={"messages": [{"role": "user", "content": request.message}]}
        )

        thread_id = run.thread_id

        # Wait for completion with proper polling
        import time
        max_wait = 60  # seconds
        start_time = time.time()

        # Poll the run status using correct SDK method
        while (time.time() - start_time) < max_wait:
            await asyncio.sleep(2)  # Poll every 2 seconds
            try:
                # Get updated run status using correct API
                run = project_client.agents.get_run(
                    thread_id=run.thread_id,
                    run_id=run.id
                )
                print(f"DEBUG: Polling - status: {run.status}")

                # Break if completed, failed, cancelled, or expired
                if run.status in ["completed", "failed", "cancelled", "expired"]:
                    break
            except Exception as e:
                print(f"DEBUG: Polling error: {str(e)}")
                break

        # Get the actual response from messages
        response_text = f"I received your message: '{request.message}'. I'm Lucy, your AI assistant!"

        # Debug: log run status
        print(f"DEBUG: Run status: {run.status}, thread_id: {run.thread_id}, run_id: {run.id}")

        if run.status == "completed":
            try:
                # Retrieve messages from the thread using correct API
                messages_list = list(project_client.agents.list_messages(
                    thread_id=run.thread_id
                ))

                print(f"DEBUG: Found {len(messages_list)} messages")

                # Get the latest assistant message
                for msg in reversed(messages_list):
                    print(f"DEBUG: Message role: {msg.role}")
                    if msg.role == "assistant":
                        for content in msg.content:
                            if hasattr(content, 'text') and hasattr(content.text, 'value'):
                                response_text = content.text.value
                                print(f"DEBUG: Got response: {response_text[:100]}...")
                                break
                        break
            except Exception as e:
                # If message retrieval fails, use a friendly fallback
                print(f"DEBUG: Error retrieving messages: {str(e)}")
                import traceback
                traceback.print_exc()
                response_text = f"抱歉，我遇到了技術問題。不過我收到了您的訊息：「{request.message}」。請再試一次！"
        else:
            print(f"DEBUG: Run did not complete. Status: {run.status}")

        # Add assistant response to history
        assistant_msg = ChatMessage(
            role="assistant",
            content=response_text,
            timestamp=datetime.now().isoformat()
        )
        conversations[user_id].append(assistant_msg)

        return ChatResponse(
            response=response_text,
            thread_id=thread_id,
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/conversations/{user_id}")
async def get_conversation_history(user_id: str):
    """Get conversation history for a user"""
    if user_id not in conversations:
        return {"user_id": user_id, "messages": []}

    return {
        "user_id": user_id,
        "messages": [msg.dict() for msg in conversations[user_id]]
    }

@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...), user_id: str = "default"):
    """Upload a file for the agent to analyze"""
    try:
        # Save file temporarily
        upload_dir = Path("/tmp/agent-lucy-uploads")
        upload_dir.mkdir(exist_ok=True)

        file_path = upload_dir / file.filename
        content = await file.read()

        with open(file_path, "wb") as f:
            f.write(content)

        return {
            "filename": file.filename,
            "size": len(content),
            "message": "File uploaded successfully. You can now ask questions about it."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: str):
    """WebSocket endpoint for real-time chat"""
    await websocket.accept()
    active_connections[user_id] = websocket

    try:
        while True:
            # Receive message
            data = await websocket.receive_text()
            message_data = json.loads(data)

            # Process message
            try:
                agent = get_agent()

                # Send typing indicator
                await websocket.send_json({"type": "typing", "typing": True})

                # Simulate processing (replace with actual agent call)
                await asyncio.sleep(1)
                response_text = f"[WebSocket] I received: {message_data.get('message')}"

                # Send response
                await websocket.send_json({
                    "type": "message",
                    "role": "assistant",
                    "content": response_text,
                    "timestamp": datetime.now().isoformat()
                })

            except Exception as e:
                await websocket.send_json({
                    "type": "error",
                    "error": str(e)
                })

    except WebSocketDisconnect:
        if user_id in active_connections:
            del active_connections[user_id]

# Mount static files
static_path = Path(__file__).parent.parent / "public"
if static_path.exists():
    app.mount("/static", StaticFiles(directory=str(static_path)), name="static")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
